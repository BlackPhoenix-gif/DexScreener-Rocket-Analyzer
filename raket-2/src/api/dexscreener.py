import os
import json
import time
import random
import logging
import asyncio
import aiohttp
from typing import Dict, List, Optional, Any, Set, Tuple
import requests
from datetime import datetime, timedelta
from tqdm import tqdm
from pathlib import Path
import argparse

from src.utils.logger import get_logger
from src.models.token import Token, TokenPair
from src.config import config
from src.analysis.perspective_tokens.token_data_saver import TokenDataSaver

logger = get_logger()

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∫–µ—à–∞ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
CACHE_DIR = Path("cache")
CACHE_DIR.mkdir(exist_ok=True)

# –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫–µ—à–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1 —á–∞—Å)
CACHE_TTL = int(os.getenv("DEXSCREENER_CACHE_TTL", "3600"))

def get_cache_path(network: str, query: str) -> Path:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–µ—à–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    """
    # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
    safe_query = "".join(c for c in query if c.isalnum() or c in ('-', '_')).rstrip()
    return CACHE_DIR / f"{network}_{safe_query}.json"

def is_cache_valid(cache_path: Path) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –ª–∏ –∫–µ—à
    """
    if not cache_path.exists():
        return False
        
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞
    cache_time = cache_path.stat().st_mtime
    current_time = time.time()
    
    return (current_time - cache_time) < CACHE_TTL

def save_to_cache(network: str, query: str, data: Dict) -> None:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –∫–µ—à
    """
    cache_path = get_cache_path(network, query)
    try:
        with open(cache_path, 'w') as f:
            json.dump({
                'timestamp': time.time(),
                'data': data
            }, f)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ –∫–µ—à: {str(e)}")

def load_from_cache(network: str, query: str) -> Optional[Dict]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–µ—à–∞
    """
    cache_path = get_cache_path(network, query)
    try:
        if is_cache_valid(cache_path):
            with open(cache_path, 'r') as f:
                cache_data = json.load(f)
                return cache_data['data']
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑ –∫–µ—à–∞: {str(e)}")
    return None

def clean_old_cache():
    """
    –£–¥–∞–ª—è–µ—Ç –≤—Å–µ —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∫–µ—à-—Ñ–∞–π–ª—ã
    """
    try:
        if not CACHE_DIR.exists():
            return
            
        current_time = time.time()
        deleted_count = 0
        
        for cache_file in CACHE_DIR.glob("*.json"):
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ–∞–π–ª–∞
                cache_time = cache_file.stat().st_mtime
                if (current_time - cache_time) >= CACHE_TTL:
                    cache_file.unlink()
                    deleted_count += 1
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –∫–µ—à-—Ñ–∞–π–ª–∞ {cache_file}: {str(e)}")
                
        if deleted_count > 0:
            logger.info(f"–£–¥–∞–ª–µ–Ω–æ {deleted_count} —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∫–µ—à-—Ñ–∞–π–ª–æ–≤")
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –∫–µ—à–∞: {str(e)}")

# –°–ª–æ–≤–∞—Ä—å —Å –±–ª–æ–∫—á–µ–π–Ω-—ç–∫—Å–ø–ª–æ—Ä–µ—Ä–∞–º–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Å–µ—Ç–µ–π
explorers = {
    'solana': 'https://solscan.io/token/',
    'base': 'https://basescan.org/token/',
    'ethereum': 'https://etherscan.io/token/',
    'bsc': 'https://bscscan.com/token/',
    'arbitrum': 'https://arbiscan.io/token/',
    'polygon': 'https://polygonscan.com/token/',
    'optimism': 'https://optimistic.etherscan.io/token/',
    'avalanche': 'https://snowtrace.io/token/',
    'fantom': 'https://ftmscan.com/token/',
    'cronos': 'https://cronoscan.com/token/',
    'pulsechain': 'https://scan.pulsechain.com/token/',
    'polygon_zkevm': 'https://zkevm.polygonscan.com/token/',
    'linea': 'https://lineascan.build/token/',
    'manta': 'https://pacific-explorer.manta.network/token/',
    'mantle': 'https://explorer.mantle.xyz/token/',
    'blast': 'https://blastscan.io/token/',
    'mode': 'https://explorer.mode.network/token/',
    'scroll': 'https://scrollscan.com/token/',
    'zksync': 'https://explorer.zksync.io/token/',
    'starknet': 'https://starkscan.co/token/',
    'celo': 'https://celoscan.io/token/',
    'gnosis': 'https://gnosisscan.io/token/',
    'core': 'https://scan.coredao.org/token/',
    'kava': 'https://explorer.kava.io/token/',
    'metis': 'https://andromeda-explorer.metis.io/token/',
    'moonbeam': 'https://moonscan.io/token/',
    'moonriver': 'https://moonriver.moonscan.io/token/',
    'harmony': 'https://explorer.harmony.one/token/',
    'aurora': 'https://aurorascan.dev/token/',
    'near': 'https://explorer.near.org/token/',
    'sui': 'https://suiexplorer.com/token/',
    'aptos': 'https://explorer.aptoslabs.com/token/',
    'sei': 'https://sei.explorers.guru/token/',
    'injective': 'https://explorer.injective.network/token/',
    'osmosis': 'https://www.mintscan.io/osmosis/token/',
    'cosmos': 'https://www.mintscan.io/cosmos/token/',
    'thorchain': 'https://viewblock.io/thorchain/token/'
}

def play_completion_sound():
    """–í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –∑–≤—É–∫ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è"""
    try:
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å –¥–æ –º–∞–∫—Å–∏–º—É–º–∞
        os.system('osascript -e "set volume output volume 100"')
        
        # –í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º –∑–≤—É–∫
        os.system('afplay /System/Library/Sounds/Glass.aiff')
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≥—Ä–æ–º–∫–æ—Å—Ç—å –Ω–∞ 40
        time.sleep(0.5)
        os.system('osascript -e "set volume output volume 40"')
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ 1 —Å–µ–∫—É–Ω–¥—É
        time.sleep(1)
        os.system('osascript -e "set volume output volume 40"')
        
        logger.info("[SYSTEM] –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω –∑–≤—É–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è. –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –≥—Ä–æ–º–∫–æ—Å—Ç—å: 40")
    except Exception as e:
        logger.error(f"[SYSTEM] –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–∏ –∑–≤—É–∫–∞: {str(e)}")

class TokenScanner:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤.
    –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –º–µ—Ç–æ–¥—ã –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ —Ç–æ–∫–µ–Ω–∞—Ö –∏ –∏—Ö –∞–Ω–∞–ª–∏–∑–∞.
    """
    
    def __init__(self, test_mode: bool = False):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤.
        
        Args:
            test_mode: –†–µ–∂–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å —Å–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–º —Å–ø–∏—Å–∫–æ–º —Ç–æ–∫–µ–Ω–æ–≤
        """
        self.base_url = "https://api.dexscreener.com/latest/dex"
        self.session = requests.Session()
        self.test_mode = test_mode
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Accept": "application/json",
            "Accept-Language": "en-US,en;q=0.9",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive"
        })
        self.timeout = int(os.getenv("DEXSCREENER_TIMEOUT", "30"))
        self.max_retries = int(os.getenv("DEXSCREENER_MAX_RETRIES", "3"))
        self.min_liquidity = float(os.getenv("DEXSCREENER_MIN_LIQUIDITY", "50" if test_mode else "250"))
        self.min_volume_24h = float(os.getenv("DEXSCREENER_MIN_VOLUME_24H", "25" if test_mode else "100"))
        self.logger = logging.getLogger("dexscreener")
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        self.log_dir = Path("logs")
        self.log_dir.mkdir(exist_ok=True)
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª—ã –ª–æ–≥–æ–≤ —Å —Ç–µ–∫—É—â–µ–π –¥–∞—Ç–æ–π
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.log_file = self.log_dir / f"token_analysis_{timestamp}.log"
        self.rockets_analysis_file = self.log_dir / f"rockets_analysis_{timestamp}.log"
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ñ–∞–π–ª–æ–≤—ã–π –ª–æ–≥–≥–µ—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–∫–µ–Ω–æ–≤
        self.file_logger = logging.getLogger("token_analysis")
        self.file_logger.setLevel(logging.DEBUG)
        file_handler = logging.FileHandler(self.log_file)
        file_handler.setLevel(logging.DEBUG)
        formatter = logging.Formatter('%(message)s')
        file_handler.setFormatter(formatter)
        self.file_logger.addHandler(file_handler)
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ñ–∞–π–ª–æ–≤—ã–π –ª–æ–≥–≥–µ—Ä –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–∫–µ—Ç
        self.rockets_logger = logging.getLogger("rockets_analysis")
        self.rockets_logger.setLevel(logging.DEBUG)
        rockets_handler = logging.FileHandler(self.rockets_analysis_file)
        rockets_handler.setLevel(logging.DEBUG)
        rockets_handler.setFormatter(formatter)
        self.rockets_logger.addHandler(rockets_handler)
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ User-Agent –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
        ]
        
        logger.info(f"[–°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ ({self.base_url})")
        logger.debug(f"[–°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï] –ù–∞—Å—Ç—Ä–æ–π–∫–∏: —Ç–∞–π–º–∞—É—Ç={self.timeout}—Å, –º–∞–∫—Å.–ø–æ–≤—Ç–æ—Ä—ã={self.max_retries}")
        self.file_logger.info("=== –ù–∞—á–∞–ª–æ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–∫–µ–Ω–æ–≤ ===")
        self.file_logger.info(f"–í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        self.file_logger.info(f"–ö—Ä–∏—Ç–µ—Ä–∏–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏:")
        self.file_logger.info(f"- –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–æ—Å—Ç —Ü–µ–Ω—ã: 5%")
        self.file_logger.info(f"- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–æ—Å—Ç —Ü–µ–Ω—ã: 1000%")
        self.file_logger.info(f"- –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å: $250")
        self.file_logger.info(f"- –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –æ–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤: $100")
        self.file_logger.info("=" * 50)
    
    def _get_tokens_to_analyze(self) -> List[Tuple[str, str]]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ (—Å–µ—Ç—å, —Ç–æ–∫–µ–Ω).
        
        Returns:
            List[Tuple[str, str]]: –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (—Å–µ—Ç—å, —Ç–æ–∫–µ–Ω)
        """
        tokens_to_analyze = []
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Å–ø–∏—Å–æ–∫ —Å–µ—Ç–µ–π –∏ —Ç–æ–∫–µ–Ω–æ–≤ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω —Ç–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º
        networks = get_test_networks() if self.test_mode else {
            'solana': [
                'SOL', 'BONK', 'RAY', 'SRM', 'MNGO', 'SAMO', 'ORCA', 'ATLAS', 'POLIS', 'GST', 'SBR',
                'JUP', 'PYTH', 'WIF', 'MYRO', 'POPCAT', 'WEN', 'SLERF', 'BOME', 'MEME'
            ],
            'base': [
                'ETH', 'WETH', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX', 'YFI', 'CRV',
                'USDC', 'USDT', 'DAI', 'WBTC', 'BAL', 'BOND', 'DPI', 'ENJ', 'GRT', 'KNC'
            ],
            'ethereum': [
                'ETH', 'WETH', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX', 'YFI', 'CRV',
                'SHIB', 'PEPE', 'DOGE', 'MATIC', 'AVAX', 'FTM', 'USDC', 'USDT', 'DAI', 'WBTC'
            ],
            'bsc': [
                'BNB', 'CAKE', 'WETH', 'WBTC', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX',
                'YFI', 'CRV', 'SHIB', 'PEPE', 'DOGE', 'USDC', 'USDT', 'DAI', 'BUSD', 'TUSD'
            ],
            'arbitrum': [
                'ETH', 'WETH', 'WBTC', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX', 'YFI',
                'CRV', 'MATIC', 'AVAX', 'FTM', 'USDC', 'USDT', 'DAI', 'BAL', 'BAT', 'BOND'
            ],
            'polygon': [
                'MATIC', 'WETH', 'WBTC', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX', 'YFI',
                'CRV', 'SHIB', 'PEPE', 'DOGE', 'USDC', 'USDT', 'DAI', 'BAL', 'BAT', 'BOND'
            ],
            'optimism': [
                'ETH', 'WETH', 'WBTC', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX', 'YFI',
                'CRV', 'MATIC', 'AVAX', 'FTM', 'USDC', 'USDT', 'DAI', 'BAL', 'BAT', 'BOND'
            ],
            'avalanche': [
                'AVAX', 'WETH', 'WBTC', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX', 'YFI',
                'CRV', 'SHIB', 'PEPE', 'DOGE', 'USDC', 'USDT', 'DAI', 'BAL', 'BAT', 'BOND'
            ],
            'fantom': [
                'FTM', 'WETH', 'WBTC', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX', 'YFI',
                'CRV', 'MATIC', 'AVAX', 'USDC', 'USDT', 'DAI', 'BAL', 'BAT', 'BOND', 'DPI'
            ],
            'cronos': [
                'CRO', 'WETH', 'WBTC', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX', 'YFI',
                'CRV', 'SHIB', 'PEPE', 'DOGE', 'USDC', 'USDT', 'DAI', 'BAL', 'BAT', 'BOND'
            ]
        }
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        for network, tokens in networks.items():
            for token in tokens:
                tokens_to_analyze.append((network, token))
                
        return tokens_to_analyze

    async def _make_async_request(self, session: aiohttp.ClientSession, endpoint: str, params: Optional[Dict] = None) -> Dict:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π HTTP –∑–∞–ø—Ä–æ—Å –∫ API DEXScreener.
        """
        url = f"{self.base_url}/{endpoint}"
        user_agent = random.choice(self.user_agents)
        headers = {"User-Agent": user_agent}
        
        for attempt in range(self.max_retries):
            try:
                async with session.get(url, params=params, headers=headers, timeout=self.timeout) as response:
                    response.raise_for_status()
                    return await response.json()
            except Exception as e:
                if attempt == self.max_retries - 1:
                    self.logger.error(f"API error: {str(e)}")
                    return {}
                await asyncio.sleep(2 ** attempt + random.random())
        
        return {}

    async def _fetch_pairs(self, session: aiohttp.ClientSession, network: str, query: str) -> List[Dict]:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–∞—Ä –¥–ª—è —Ç–æ–∫–µ–Ω–∞ –≤ —Å–µ—Ç–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–µ—à–∞.
        """
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
            cached_data = load_from_cache(network, query)
            if cached_data:
                logger.debug(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è '{query}' –≤ —Å–µ—Ç–∏ {network}")
                return cached_data.get("pairs", [])
            
            # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –≤ –∫–µ—à–µ, –¥–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å –∫ API
            response = await self._make_async_request(session, "search", {
                "q": query,
                "chain": network
            })
            
            if not response or "pairs" not in response:
                self.logger.warning(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è '{query}' –≤ —Å–µ—Ç–∏ {network}")
                return []
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∫–µ—à
            save_to_cache(network, query, response)
            
            return response.get("pairs", [])
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ '{query}' –≤ —Å–µ—Ç–∏ {network}: {str(e)}")
            return []

    async def get_latest_token_profiles_async(self) -> List[Dict]:
        """
        –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π —Ç–æ–∫–µ–Ω–æ–≤.
        """
        logger.info("[–°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï] –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π —Ç–æ–∫–µ–Ω–æ–≤")
        try:
            networks = get_test_networks() if self.test_mode else {
                'solana': [
                    'SOL', 'BONK', 'RAY', 'SRM', 'MNGO', 'SAMO', 'ORCA', 'ATLAS', 'POLIS', 'GST', 'SBR',
                    'JUP', 'PYTH', 'WIF', 'MYRO', 'POPCAT', 'WEN', 'SLERF', 'BOME', 'MEME'
                ],
                'base': [
                    'ETH', 'WETH', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX', 'YFI', 'CRV',
                    'USDC', 'USDT', 'DAI', 'WBTC', 'WETH', 'BAL', 'BOND', 'DPI', 'ENJ', 'GRT',
                    'KNC', 'LDO', 'LRC', 'MKR', 'NMR', 'OXT', 'PAX', 'REN', 'REP', 'SUSHI',
                    'SXP', 'TUSD', 'UMA', 'UNI', 'USDT', 'WBTC', 'WETH', 'YFI', 'ZRX', 'BAL',
                    'BAT', 'BOND', 'DPI', 'ENJ', 'GRT', 'KNC', 'LDO', 'LRC', 'NMR', 'OXT',
                    'PAX', 'REN', 'REP', 'SUSHI', 'SXP', 'TUSD', 'UMA', 'ZRX', 'BAL', 'BAT'
                ],
                'ethereum': [
                    'ETH', 'WETH', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX', 'YFI', 'CRV',
                    'SHIB', 'PEPE', 'DOGE', 'MATIC', 'AVAX', 'FTM', 'USDC', 'USDT', 'DAI', 'WBTC',
                    'BAL', 'BAT', 'BOND', 'DPI', 'ENJ', 'GRT', 'KNC', 'LDO', 'LRC', 'NMR',
                    'OXT', 'PAX', 'REN', 'REP', 'SUSHI', 'SXP', 'TUSD', 'UMA', 'ZRX', 'BAL',
                    'BAT', 'BOND', 'DPI', 'ENJ', 'GRT', 'KNC', 'LDO', 'LRC', 'NMR', 'OXT',
                    'PAX', 'REN', 'REP', 'SUSHI', 'SXP', 'TUSD', 'UMA', 'ZRX', 'BAL', 'BAT'
                ],
                'bsc': [
                    'BNB', 'CAKE', 'WETH', 'WBTC', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX',
                    'YFI', 'CRV', 'SHIB', 'PEPE', 'DOGE', 'USDC', 'USDT', 'DAI', 'BUSD', 'TUSD',
                    'BAL', 'BAT', 'BOND', 'DPI', 'ENJ', 'GRT', 'KNC', 'LDO', 'LRC', 'NMR',
                    'OXT', 'PAX', 'REN', 'REP', 'SUSHI', 'SXP', 'UMA', 'ZRX', 'BAL', 'BAT',
                    'BOND', 'DPI', 'ENJ', 'GRT', 'KNC', 'LDO', 'LRC', 'NMR', 'OXT', 'PAX',
                    'REN', 'REP', 'SUSHI', 'SXP', 'TUSD', 'UMA', 'ZRX', 'BAL', 'BAT', 'BOND'
                ],
                'arbitrum': [
                    'ETH', 'WETH', 'WBTC', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX', 'YFI',
                    'CRV', 'MATIC', 'AVAX', 'FTM', 'USDC', 'USDT', 'DAI', 'BAL', 'BAT', 'BOND',
                    'DPI', 'ENJ', 'GRT', 'KNC', 'LDO', 'LRC', 'NMR', 'OXT', 'PAX', 'REN',
                    'REP', 'SUSHI', 'SXP', 'TUSD', 'UMA', 'ZRX', 'BAL', 'BAT', 'BOND', 'DPI',
                    'ENJ', 'GRT', 'KNC', 'LDO', 'LRC', 'NMR', 'OXT', 'PAX', 'REN', 'REP',
                    'SUSHI', 'SXP', 'TUSD', 'UMA', 'ZRX', 'BAL', 'BAT', 'BOND', 'DPI', 'ENJ'
                ],
                'polygon': [
                    'MATIC', 'WETH', 'WBTC', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX', 'YFI',
                    'CRV', 'SHIB', 'PEPE', 'DOGE', 'USDC', 'USDT', 'DAI', 'BAL', 'BAT', 'BOND',
                    'DPI', 'ENJ', 'GRT', 'KNC', 'LDO', 'LRC', 'NMR', 'OXT', 'PAX', 'REN',
                    'REP', 'SUSHI', 'SXP', 'TUSD', 'UMA', 'ZRX', 'BAL', 'BAT', 'BOND', 'DPI',
                    'ENJ', 'GRT', 'KNC', 'LDO', 'LRC', 'NMR', 'OXT', 'PAX', 'REN', 'REP',
                    'SUSHI', 'SXP', 'TUSD', 'UMA', 'ZRX', 'BAL', 'BAT', 'BOND', 'DPI', 'ENJ'
                ],
                'optimism': [
                    'ETH', 'WETH', 'WBTC', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX', 'YFI',
                    'CRV', 'MATIC', 'AVAX', 'FTM', 'USDC', 'USDT', 'DAI', 'BAL', 'BAT', 'BOND',
                    'DPI', 'ENJ', 'GRT', 'KNC', 'LDO', 'LRC', 'NMR', 'OXT', 'PAX', 'REN',
                    'REP', 'SUSHI', 'SXP', 'TUSD', 'UMA', 'ZRX', 'BAL', 'BAT', 'BOND', 'DPI',
                    'ENJ', 'GRT', 'KNC', 'LDO', 'LRC', 'NMR', 'OXT', 'PAX', 'REN', 'REP',
                    'SUSHI', 'SXP', 'TUSD', 'UMA', 'ZRX', 'BAL', 'BAT', 'BOND', 'DPI', 'ENJ'
                ],
                'avalanche': [
                    'AVAX', 'WETH', 'WBTC', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX', 'YFI',
                    'CRV', 'SHIB', 'PEPE', 'DOGE', 'USDC', 'USDT', 'DAI', 'BAL', 'BAT', 'BOND',
                    'DPI', 'ENJ', 'GRT', 'KNC', 'LDO', 'LRC', 'NMR', 'OXT', 'PAX', 'REN',
                    'REP', 'SUSHI', 'SXP', 'TUSD', 'UMA', 'ZRX', 'BAL', 'BAT', 'BOND', 'DPI',
                    'ENJ', 'GRT', 'KNC', 'LDO', 'LRC', 'NMR', 'OXT', 'PAX', 'REN', 'REP',
                    'SUSHI', 'SXP', 'TUSD', 'UMA', 'ZRX', 'BAL', 'BAT', 'BOND', 'DPI', 'ENJ'
                ],
                'fantom': [
                    'FTM', 'WETH', 'WBTC', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX', 'YFI',
                    'CRV', 'MATIC', 'AVAX', 'USDC', 'USDT', 'DAI', 'BAL', 'BAT', 'BOND', 'DPI',
                    'ENJ', 'GRT', 'KNC', 'LDO', 'LRC', 'NMR', 'OXT', 'PAX', 'REN', 'REP',
                    'SUSHI', 'SXP', 'TUSD', 'UMA', 'ZRX', 'BAL', 'BAT', 'BOND', 'DPI', 'ENJ',
                    'GRT', 'KNC', 'LDO', 'LRC', 'NMR', 'OXT', 'PAX', 'REN', 'REP', 'SUSHI',
                    'SXP', 'TUSD', 'UMA', 'ZRX', 'BAL', 'BAT', 'BOND', 'DPI', 'ENJ', 'GRT'
                ],
                'cronos': [
                    'CRO', 'WETH', 'WBTC', 'LINK', 'UNI', 'AAVE', 'COMP', 'MKR', 'SNX', 'YFI',
                    'CRV', 'SHIB', 'PEPE', 'DOGE', 'USDC', 'USDT', 'DAI', 'BAL', 'BAT', 'BOND',
                    'DPI', 'ENJ', 'GRT', 'KNC', 'LDO', 'LRC', 'NMR', 'OXT', 'PAX', 'REN',
                    'REP', 'SUSHI', 'SXP', 'TUSD', 'UMA', 'ZRX', 'BAL', 'BAT', 'BOND', 'DPI',
                    'ENJ', 'GRT', 'KNC', 'LDO', 'LRC', 'NMR', 'OXT', 'PAX', 'REN', 'REP',
                    'SUSHI', 'SXP', 'TUSD', 'UMA', 'ZRX', 'BAL', 'BAT', 'BOND', 'DPI', 'ENJ'
                ]
            }
            
            all_pairs = []
            total_requests = sum(len(queries) for queries in networks.values())
            logger.info(f"[–°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï] –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {total_requests}")
            
            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫–∏ –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º
            found_tokens = 0
            filtered_tokens = 0
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä —Å –Ω—É–ª—è
            with tqdm(total=total_requests, desc="–ü–æ–∏—Å–∫ —Ç–æ–∫–µ–Ω–æ–≤", unit="–∑–∞–ø—Ä–æ—Å", 
                     position=0, leave=True, 
                     bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}, {postfix}]') as pbar:
                async with aiohttp.ClientSession() as session:
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–µ—Ç–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
                    for network, queries in networks.items():
                        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–∫–µ–Ω—ã –≤ –∫–∞–∂–¥–æ–π —Å–µ—Ç–∏ —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π
                        for query in queries:
                            try:
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à –ø–µ—Ä–µ–¥ –∑–∞–ø—Ä–æ—Å–æ–º
                                cached_data = load_from_cache(network, query)
                                if cached_data:
                                    # –î–ª—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ –¥–µ–ª–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É
                                    pairs = cached_data.get("pairs", [])
                                else:
                                    # –ó–∞–¥–µ—Ä–∂–∫–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ API
                                    await asyncio.sleep(random.uniform(1, 3))
                                    pairs = await self._fetch_pairs(session, network, query)
                                
                                if pairs:
                                    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–∞—Ä—ã –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º
                                    filtered_pairs = [pair for pair in pairs if self._is_rocket_token(pair)]
                                    found_tokens += len(pairs)
                                    filtered_tokens += len(filtered_pairs)
                                    all_pairs.extend(filtered_pairs)  # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–∞—Ä—ã
                                    self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(pairs)} –ø–∞—Ä, –∏–∑ –Ω–∏—Ö {len(filtered_pairs)} –ø—Ä–æ—à–ª–∏ —Ñ–∏–ª—å—Ç—Ä –¥–ª—è '{query}' –≤ —Å–µ—Ç–∏ {network}")
                                pbar.set_postfix({'–í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤': found_tokens, '–ü—Ä–æ—à–ª–∏ —Ñ–∏–ª—å—Ç—Ä': filtered_tokens})
                                pbar.update(1)
                            except Exception as e:
                                self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ '{query}' –≤ —Å–µ—Ç–∏ {network}: {str(e)}")
                                pbar.update(1)
            
            if not all_pairs:
                self.logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –ø–∞—Ä—ã")
                return []
            
            # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ –∞–¥—Ä–µ—Å—É —Ç–æ–∫–µ–Ω–∞
            unique_pairs = {pair["baseToken"]["address"]: pair for pair in all_pairs}.values()
            self.logger.info(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(unique_pairs)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ä")
            return list(unique_pairs)
            
        except Exception as e:
            self.logger.error(f"[–°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–æ—Ñ–∏–ª–µ–π —Ç–æ–∫–µ–Ω–æ–≤: {str(e)}")
            return []

    def get_token_pairs(self, chain_id: str, token_address: str) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –≤—Å–µ –ø–∞—Ä—ã –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞.
        
        Args:
            chain_id: –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –±–ª–æ–∫—á–µ–π–Ω–∞
            token_address: –ê–¥—Ä–µ—Å —Ç–æ–∫–µ–Ω–∞
            
        Returns:
            List[Dict]: –°–ø–∏—Å–æ–∫ –ø–∞—Ä —Ç–æ–∫–µ–Ω–∞
        """
        logger.info(f"[–°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï] –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä –¥–ª—è —Ç–æ–∫–µ–Ω–∞ {token_address} –Ω–∞ {chain_id}")
        try:
            return self._make_request(f"tokens/{chain_id}/{token_address}")
        except Exception as e:
            self.logger.error(f"[–°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø–∞—Ä —Ç–æ–∫–µ–Ω–∞: {str(e)}")
            return []
    
    def _log_token_analysis(self, token: Dict, profile: Dict, reason: str = None):
        """
        –õ–æ–≥–∏—Ä—É–µ—Ç –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–∫–µ–Ω–∞ –≤ —Ñ–∞–π–ª
        """
        self.file_logger.info("\n" + "=" * 30)
        self.file_logger.info(f"–¢–æ–∫–µ–Ω: {token['symbol']} ({token['address'][:8]}...)")
        self.file_logger.info(f"–°–µ—Ç—å: {profile['chainId']}")
        
        # –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
        price_change_24h = float(profile.get("priceChange", {}).get("h24", 0))
        liquidity_usd = float(profile.get("liquidity", {}).get("usd", 0))
        volume_24h = float(profile.get("volume", {}).get("h24", 0))
        
        self.file_logger.info(f"–†–æ—Å—Ç 24—á: {price_change_24h:.2f}% | –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å: ${liquidity_usd:.2f} | –û–±—ä–µ–º: ${volume_24h:.2f}")
        
        if reason:
            self.file_logger.info(f"‚ùå –û—Ç–∫–ª–æ–Ω–µ–Ω: {reason}")
        else:
            self.file_logger.info("‚úÖ –ü—Ä–∏–Ω—è—Ç")
        
        self.file_logger.info("=" * 30)

    def _analyze_rocket(self, token: Dict) -> str:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—É—é —Ä–∞–∫–µ—Ç—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç
        """
        profile = token['profile']
        price_change_24h = token['price_change_24h']
        liquidity_usd = token['liquidity_usd']
        volume_24h = token['volume_24h']
        age_hours = token['age_hours']
        price_usd = float(profile.get('priceUsd', 0))
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        volume_to_liquidity_ratio = volume_24h / liquidity_usd if liquidity_usd > 0 else 0
        age_days = round(age_hours / 24, 2)
        
        # –ê–Ω–∞–ª–∏–∑ –∏–º–ø—É–ª—å—Å–∞ —Ü–µ–Ω—ã
        price_changes = profile.get('priceChange', {})
        momentum = (
            float(price_changes.get('h1', 0)) * 0.2 +
            float(price_changes.get('h6', 0)) * 0.3 +
            float(price_changes.get('h24', 0)) * 0.5
        )
        
        # –†–∞—Å—á–µ—Ç —Å–∫–æ—Ä–æ–≤
        liquidity_score = min(100, (liquidity_usd / 100000) * 100)
        volume_score = min(100, (volume_24h / 50000) * 100)
        momentum_score = min(100, max(0, 50 + momentum))
        stability_score = min(100, volume_to_liquidity_ratio * 100)
        age_score = min(100, (age_days / 30) * 100)
        
        # –û–±—â–∏–π —Ä–∏—Å–∫-—Å–∫–æ—Ä (0-100, —á–µ–º –Ω–∏–∂–µ —Ç–µ–º –ª—É—á—à–µ)
        risk_score = (
            (100 - liquidity_score) * 0.3 +
            (100 - volume_score) * 0.2 +
            (100 - stability_score) * 0.2 +
            (100 - age_score) * 0.15 +
            (100 - momentum_score) * 0.15
        )
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π
        liquidity_category = "–≤—ã—Å–æ–∫–∞—è" if liquidity_usd > 100000 else "—Å—Ä–µ–¥–Ω—è—è" if liquidity_usd > 10000 else "–Ω–∏–∑–∫–∞—è"
        volume_category = "–≤—ã—Å–æ–∫–∏–π" if volume_24h > 100000 else "—Å—Ä–µ–¥–Ω–∏–π" if volume_24h > 10000 else "–Ω–∏–∑–∫–∏–π"
        growth_category = "–≤—ã—Å–æ–∫–∏–π" if price_change_24h > 50 else "—É–º–µ—Ä–µ–Ω–Ω—ã–π" if price_change_24h > 20 else "–Ω–∏–∑–∫–∏–π"
        risk_category = "–Ω–∏–∑–∫–∏–π" if risk_score < 30 else "—Å—Ä–µ–¥–Ω–∏–π" if risk_score < 60 else "–≤—ã—Å–æ–∫–∏–π"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑
        analysis = f"""
# –ê–Ω–∞–ª–∏–∑ —Ä–∞–∫–µ—Ç—ã: {token['symbol']} ({token['network']})

## –ö–ª—é—á–µ–≤—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏:
- **–†–æ—Å—Ç 24—á:** {price_change_24h:.2f}% ({growth_category})
- **–õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å:** ${liquidity_usd:,.2f} ({liquidity_category})
- **–û–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤ 24—á:** ${volume_24h:,.2f} ({volume_category})
- **–í–æ–∑—Ä–∞—Å—Ç:** {age_hours:.2f} —á–∞—Å–æ–≤ (‚âà{age_days} –¥–Ω–µ–π)
- **–¶–µ–Ω–∞:** ${price_usd:.8f}
- **–°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –æ–±—ä–µ–º–∞ –∫ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏:** {volume_to_liquidity_ratio:.3f}

## –ú–µ—Ç—Ä–∏–∫–∏ —Ä–∏—Å–∫–∞:
- **–û–±—â–∏–π —Ä–∏—Å–∫:** {risk_score:.1f}% ({risk_category})
- **–°–∫–æ—Ä –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏:** {liquidity_score:.1f}%
- **–°–∫–æ—Ä –æ–±—ä–µ–º–∞:** {volume_score:.1f}%
- **–°–∫–æ—Ä —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏:** {stability_score:.1f}%
- **–°–∫–æ—Ä –≤–æ–∑—Ä–∞—Å—Ç–∞:** {age_score:.1f}%
- **–°–∫–æ—Ä –∏–º–ø—É–ª—å—Å–∞:** {momentum_score:.1f}%

## –ê–Ω–∞–ª–∏–∑:
"""
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π
        if volume_to_liquidity_ratio < 0.1:
            analysis += "- –ù–∏–∑–∫–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –æ–±—ä–µ–º–∞ –∫ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –≤–æ–∑–º–æ–∂–Ω—É—é –Ω–∏–∑–∫—É—é —Ä–µ–∞–ª—å–Ω—É—é —Ç–æ—Ä–≥–æ–≤—É—é –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å\n"
        elif volume_to_liquidity_ratio > 1:
            analysis += "- –í—ã—Å–æ–∫–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –æ–±—ä–µ–º–∞ –∫ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –∞–∫—Ç–∏–≤–Ω—É—é —Ç–æ—Ä–≥–æ–≤–ª—é\n"
            
        if age_days < 7:
            analysis += "- –ù–æ–≤—ã–π —Ç–æ–∫–µ–Ω —Å –≤—ã—Å–æ–∫–∏–º –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–º —Ä–æ—Å—Ç–∞\n"
        elif age_days < 30:
            analysis += "- –û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –Ω–æ–≤—ã–π —Ç–æ–∫–µ–Ω\n"
        else:
            analysis += "- –ó—Ä–µ–ª—ã–π —Ç–æ–∫–µ–Ω —Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–π –∏—Å—Ç–æ—Ä–∏–µ–π\n"
            
        if liquidity_usd < 10000:
            analysis += "- –ù–∏–∑–∫–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å —Å–æ–∑–¥–∞–µ—Ç —Ä–∏—Å–∫ –≤—ã—Å–æ–∫–æ–≥–æ –ø—Ä–æ—Å–∫–∞–ª—å–∑—ã–≤–∞–Ω–∏—è\n"
        elif liquidity_usd > 100000:
            analysis += "- –í—ã—Å–æ–∫–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å —Ç–æ—Ä–≥–æ–≤–ª–∏\n"
            
        if price_usd < 0.0001:
            analysis += "- –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è —Ü–µ–Ω–∞ –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ –≤—ã—Å–æ–∫—É—é –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å\n"
        elif price_usd > 1:
            analysis += "- –í—ã—Å–æ–∫–∞—è —Ü–µ–Ω–∞ –º–æ–∂–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞—Ç—å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ä–æ—Å—Ç–∞\n"

        analysis += "\n## –†–∏—Å–∫–∏:\n"
        if liquidity_usd < 10000:
            analysis += "- –†–∏—Å–∫ –≤—ã—Å–æ–∫–æ–≥–æ –ø—Ä–æ—Å–∫–∞–ª—å–∑—ã–≤–∞–Ω–∏—è –ø—Ä–∏ –≤—Ö–æ–¥–µ/–≤—ã—Ö–æ–¥–µ\n"
        if volume_24h < 10000:
            analysis += "- –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–π –Ω–∞ –Ω–∏–∑–∫–æ–æ–±—ä–µ–º–Ω–æ–º —Ä—ã–Ω–∫–µ\n"
        if price_change_24h > 100:
            analysis += "- –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –æ—Ç–∫–∞—Ç–∞ –ø–æ—Å–ª–µ —Ä–µ–∑–∫–æ–≥–æ —Ä–æ—Å—Ç–∞\n"
        if age_days < 7:
            analysis += "- –†–∏—Å–∫ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –Ω–æ–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞\n"
            
        analysis += "\n## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:\n"
        if risk_score < 30:
            analysis += "- –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –¥–ª—è —Å—Ä–µ–¥–Ω–∏—Ö –∏ –∫—Ä—É–ø–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π\n"
            analysis += "- –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏: 5-10% –æ—Ç –ø–æ—Ä—Ç—Ñ–µ–ª—è\n"
        elif risk_score < 60:
            analysis += "- –ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –ø–æ–∑–∏—Ü–∏–π\n"
            analysis += "- –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏: 2-5% –æ—Ç –ø–æ—Ä—Ç—Ñ–µ–ª—è\n"
        else:
            analysis += "- –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—á–µ–Ω—å –Ω–µ–±–æ–ª—å—à–∏—Ö —Å–ø–µ–∫—É–ª—è—Ç–∏–≤–Ω—ã—Ö –ø–æ–∑–∏—Ü–∏–π\n"
            analysis += "- –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π —Ä–∞–∑–º–µ—Ä –ø–æ–∑–∏—Ü–∏–∏: –¥–æ 1% –æ—Ç –ø–æ—Ä—Ç—Ñ–µ–ª—è\n"
            
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—Ö–æ–¥—É
        analysis += "\n## –°—Ç—Ä–∞—Ç–µ–≥–∏—è –≤—Ö–æ–¥–∞:\n"
        if momentum > 0:
            analysis += "- –¢–æ–∫–µ–Ω –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –∏–º–ø—É–ª—å—Å, –º–æ–∂–Ω–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤—Ö–æ–¥\n"
        else:
            analysis += "- –¢–æ–∫–µ–Ω –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –∏–º–ø—É–ª—å—Å, –ª—É—á—à–µ –¥–æ–∂–¥–∞—Ç—å—Å—è —Ä–∞–∑–≤–æ—Ä–æ—Ç–∞\n"
            
        if price_change_24h > 50:
            analysis += "- –í—ã—Å–æ–∫–∏–π —Ä–æ—Å—Ç –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –æ—Ç–∫–∞—Ç—É, –ª—É—á—à–µ –¥–æ–∂–¥–∞—Ç—å—Å—è –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏\n"
        elif price_change_24h < 20:
            analysis += "- –£–º–µ—Ä–µ–Ω–Ω—ã–π —Ä–æ—Å—Ç –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤—Ö–æ–¥\n"
            
        return analysis

    async def find_rocket_tokens(self, max_age_hours: int = 24) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ —Ç–æ–∫–µ–Ω–æ–≤-—Ä–∞–∫–µ—Ç —Å —É—á–µ—Ç–æ–º –≤—Å–µ—Ö –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤.
        """
        try:
            self.logger.info("[–°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï] –ù–∞—á–∞–ª–æ –ø–æ–∏—Å–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤-—Ä–∞–∫–µ—Ç")
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ç–æ–∫–µ–Ω—ã —á–µ—Ä–µ–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥
            tokens = await self.get_latest_token_profiles_async()
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–∫–µ–Ω—ã –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º —Ä–∞–∫–µ—Ç—ã
            rocket_tokens = []
            for token_data in tokens:
                if self._is_rocket_token(token_data, max_age_hours):
                    rocket_tokens.append(token_data)
            
            self.logger.info(f"[–°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï] –ù–∞–π–¥–µ–Ω–æ {len(rocket_tokens)} —Ç–æ–∫–µ–Ω–æ–≤-—Ä–∞–∫–µ—Ç")
            return rocket_tokens
                
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ä–∞–∫–µ—Ç: {str(e)}")
            return []

    def _is_rocket_token(self, token: Dict, max_age_hours: int = None) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–æ–∫–µ–Ω —Ä–∞–∫–µ—Ç–æ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –µ–≥–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫.
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –±–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞
            base_token = token.get('baseToken', {})
            quote_token = token.get('quoteToken', {})
            
            # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø—É—Ç—è–º–∏ –≤ JSON
            try:
                price_change = float(token.get('priceChange', {}).get('h24', 0))
            except (TypeError, ValueError, AttributeError):
                try:
                    price_change = float(token.get('priceChange24h', 0))
                except (TypeError, ValueError):
                    price_change = 0
                
            try:
                liquidity = float(token.get('liquidity', {}).get('usd', 0))
            except (TypeError, ValueError, AttributeError):
                try:
                    liquidity = float(token.get('liquidity', 0))
                except (TypeError, ValueError):
                    liquidity = 0
                
            try:
                volume_24h = float(token.get('volume', {}).get('h24', 0))
            except (TypeError, ValueError, AttributeError):
                try:
                    volume_24h = float(token.get('volume24h', 0))
                except (TypeError, ValueError):
                    volume_24h = 0
                
            try:
                age_hours = float(token.get('ageHours', 0))
            except (TypeError, ValueError):
                age_hours = 0
            
            # –õ–æ–≥–∏—Ä—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            self.logger.info(f"\n–ê–Ω–∞–ª–∏–∑ —Ç–æ–∫–µ–Ω–∞ {base_token.get('symbol', 'Unknown')}:")
            self.logger.info(f"- –†–æ—Å—Ç —Ü–µ–Ω—ã: {price_change}%")
            self.logger.info(f"- –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å: ${liquidity:,.2f}")
            self.logger.info(f"- –û–±—ä–µ–º 24—á: ${volume_24h:,.2f}")
            self.logger.info(f"- –í–æ–∑—Ä–∞—Å—Ç: {age_hours:.1f}—á")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
            if liquidity < self.min_liquidity:
                self.logger.info(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å: ${liquidity:,.2f} < ${self.min_liquidity:,.2f}")
                return False
                
            if volume_24h < self.min_volume_24h:
                self.logger.info(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –æ–±—ä–µ–º: ${volume_24h:,.2f} < ${self.min_volume_24h:,.2f}")
                return False
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–æ—Å—Ç —Ü–µ–Ω—ã
            min_price_change = 2 if self.test_mode else 20  # 2% –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞, 20% –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ
            if price_change < min_price_change:
                self.logger.info(f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π —Ä–æ—Å—Ç —Ü–µ–Ω—ã: {price_change}% (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å > {min_price_change}%)")
                return False
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–æ–∑—Ä–∞—Å—Ç —Ç–æ–∫–µ–Ω–∞
            if max_age_hours and age_hours > max_age_hours:
                self.logger.info(f"‚ùå –¢–æ–∫–µ–Ω —Å–ª–∏—à–∫–æ–º —Å—Ç–∞—Ä—ã–π: {age_hours:.1f}—á > {max_age_hours}—á")
                return False
                
            # –ï—Å–ª–∏ –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã
            self.logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Ä–∞–∫–µ—Ç–∞: {base_token.get('symbol', 'Unknown')}")
            self.logger.info(f"   - –†–æ—Å—Ç: {price_change}%")
            self.logger.info(f"   - –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å: ${liquidity:,.2f}")
            self.logger.info(f"   - –û–±—ä–µ–º: ${volume_24h:,.2f}")
            self.logger.info(f"   - –í–æ–∑—Ä–∞—Å—Ç: {age_hours:.1f}—á")
            return True
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ç–æ–∫–µ–Ω–∞-—Ä–∞–∫–µ—Ç—ã: {str(e)}")
            self.logger.error(f"–î–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞: {json.dumps(token, indent=2)}")
            return False

def filter_duplicate_tokens(tokens):
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã —Ç–æ–∫–µ–Ω–æ–≤, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –≤–µ—Ä—Å–∏—é —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å—é.
    
    Args:
        tokens (list): –°–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤
        
    Returns:
        list: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    """
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å—é
    unique_tokens = {}
    
    for token in tokens:
        symbol = token['symbol']
        liquidity = token['liquidity_usd']
        
        # –ï—Å–ª–∏ —Ç–æ–∫–µ–Ω —Å —Ç–∞–∫–∏–º —Å–∏–º–≤–æ–ª–æ–º —É–∂–µ –µ—Å—Ç—å, —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
        if symbol in unique_tokens:
            if liquidity > unique_tokens[symbol]['liquidity_usd']:
                unique_tokens[symbol] = token
        else:
            unique_tokens[symbol] = token
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤
    return list(unique_tokens.values())

def get_test_networks():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–µ—Ç–µ–π –∏ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞
    """
    return {
        'solana': ['SOL', 'BONK', 'RAY', 'SRM', 'MNGO'],
        'ethereum': ['ETH', 'LINK', 'UNI', 'AAVE', 'COMP'],
        'bsc': ['BNB', 'CAKE', 'WBTC', 'LINK', 'UNI'],
        'polygon': ['MATIC', 'WETH', 'LINK', 'UNI', 'AAVE'],
        'arbitrum': ['ETH', 'WBTC', 'LINK', 'UNI', 'AAVE']
    }

def get_test_config():
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —Å –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–º–∏ –∫—Ä–∏—Ç–µ—Ä–∏—è–º–∏ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞
    """
    return {
        "min_price_change": 2,  # 2% –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞
        "max_price_change": 999999,  # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–æ
        "min_liquidity": 50,    # –ë—ã–ª–æ 250
        "min_volume": 25,       # –ë—ã–ª–æ 100
        "networks": list(get_test_networks().keys())
    }

async def test_api(test_mode: bool = False):
    api = TokenScanner(test_mode=test_mode)
    
    # –ü–æ–∏—Å–∫ —Ä–∞–∫–µ—Ç
    print("\n–ü–æ–∏—Å–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Ä–∞–∫–µ—Ç...")
    if test_mode:
        print("üîç –¢–µ—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º: —Å–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –∏ –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏")
        config = get_test_config()
    else:
        config = {
            "min_price_change": 5,  # 5% –¥–ª—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞
            "max_price_change": 999999,  # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –Ω–µ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–æ
            "min_liquidity": 250,
            "min_volume": 100,
            "networks": list(explorers.keys())
        }
    
    rockets = await api.find_rocket_tokens()
    
    if not rockets:
        print("\n–†–∞–∫–µ—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return
        
    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ä–∞–∫–µ—Ç –ø–æ —Å—É—Ç–æ—á–Ω–æ–º—É –ø—Ä–∏—Ä–æ—Å—Ç—É
    rockets.sort(key=lambda x: x['price_change_24h'], reverse=True)
    
    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤–µ—Ä—Å–∏–∏ —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å—é
    unique_rockets = filter_duplicate_tokens(rockets)
    
    print(f"\n–ù–∞–π–¥–µ–Ω–æ –≤—Å–µ–≥–æ {len(rockets)} –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Ä–∞–∫–µ—Ç")
    print(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(unique_rockets)}")
    print(f"–í—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ä–∞–∫–µ—Ç—ã (–±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤):\n")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON
    output_dir = Path("results")
    saver = TokenDataSaver(output_dir)
    json_path = saver.save_tokens_data(unique_rockets, config)
    print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {json_path}")
    
    # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–∞–∂–¥–æ–π —Ä–∞–∫–µ—Ç–µ
    for i, token in enumerate(unique_rockets, 1):
        print(f"{'='*80}")
        print(f"üöÄ #{i} | {token['symbol']} | –°–µ—Ç—å: {token['network']}")
        print(f"{'='*80}")
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
        profile = token['profile']
        price_changes = profile.get('priceChange', {})
        
        print(f"üìà –†–æ—Å—Ç: 24—á: {price_changes.get('h24', 0):+.2f}% | 1—á: {price_changes.get('h1', 0):+.2f}%")
        print(f"üí∞ –¶–µ–Ω–∞: ${profile.get('priceUsd', '0')} | –õ–∏–∫–≤: ${token['liquidity_usd']:,.2f} | –û–±—ä–µ–º 24—á: ${token['volume_24h']:,.2f}")
        print(f"‚è∞ –í–æ–∑—Ä–∞—Å—Ç: {token['age_hours']:.1f}—á | DEX: {profile.get('dexId', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')}")
        
        # –°—Å—ã–ª–∫–∏
        print("\nüîó –°—Å—ã–ª–∫–∏:")
        
        # DEXScreener
        print(f"üìä DEXScreener: https://dexscreener.com/{token['network'].lower()}/{token['address']}")
        
        # –°—Å—ã–ª–∫–∞ –Ω–∞ DEX
        dex_id = profile.get('dexId', '').lower()
        if dex_id == 'pancakeswap':
            print(f"ü•û PancakeSwap: https://pancakeswap.finance/swap?outputCurrency={token['address']}")
        elif dex_id == 'raydium':
            print(f"üåü Raydium: https://raydium.io/swap/?inputCurrency=sol&outputCurrency={token['address']}")
        elif dex_id == 'uniswap':
            print(f"ü¶Ñ Uniswap: https://app.uniswap.org/#/swap?outputCurrency={token['address']}")
        elif dex_id == 'sushi':
            print(f"üç£ SushiSwap: https://app.sushi.com/swap?outputCurrency={token['address']}")
        
        # –°—Å—ã–ª–∫–∞ –Ω–∞ –±–ª–æ–∫—á–µ–π–Ω-—ç–∫—Å–ø–ª–æ—Ä–µ—Ä
        network = token['network'].lower()
        if network in explorers:
            print(f"üîç Explorer: {explorers[network]}{token['address']}")
            
        print()

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='–ü–æ–∏—Å–∫ —Ä–∞–∫–µ—Ç –Ω–∞ DEX')
    parser.add_argument('-test', action='store_true', help='–ó–∞–ø—É—Å–∫ –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ (—Å–æ–∫—Ä–∞—â–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –∏ –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏)')
    args = parser.parse_args()
    
    asyncio.run(test_api(test_mode=args.test)) 