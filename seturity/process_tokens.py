import asyncio
import json
import os
from typing import List, Dict, Any
from free_analyzer import FreeTokenAnalyzer

class TokenProcessor:
    def __init__(self):
        self.analyzer = FreeTokenAnalyzer()
    
    async def process_tokens_file(self, input_file: str, output_file: str):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ —Å —Ç–æ–∫–µ–Ω–∞–º–∏"""
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {input_file}...")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        tokens_data = self.load_tokens_data(input_file)
        if not tokens_data:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ")
            return
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–æ–≤ (–∏—Å–∫–ª—é—á–∞–µ–º –ø–æ–º–µ—á–µ–Ω–Ω—ã–µ –∫–∞–∫ scam)
        tokens_to_analyze = self.filter_tokens(tokens_data)
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(tokens_to_analyze)} —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∞–¥—Ä–µ—Å–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤
        token_addresses = []
        for token in tokens_to_analyze:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –∞–¥—Ä–µ—Å–æ–≤
            address = None
            if isinstance(token, dict):
                # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç —Å basic_info
                if 'basic_info' in token and 'address' in token['basic_info']:
                    address = token['basic_info']['address']
                # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç
                elif 'address' in token:
                    address = token['address']
                elif 'token_address' in token:
                    address = token['token_address']
            
            if address:
                token_addresses.append(address)
        
        if not token_addresses:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –∞–¥—Ä–µ—Å–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤")
            return
        
        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        unique_addresses = list(set(token_addresses))
        print(f"üìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º {len(unique_addresses)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤...")
        
        # –ê–Ω–∞–ª–∏–∑ —Ç–æ–∫–µ–Ω–æ–≤
        analyzed_tokens = []
        for i, token_address in enumerate(unique_addresses, 1):
            print(f"üîç –ê–Ω–∞–ª–∏–∑ {i}/{len(unique_addresses)}: {token_address}")
            
            try:
                # –ê–Ω–∞–ª–∏–∑ —Ç–æ–∫–µ–Ω–∞
                report = await self.analyzer.analyze_token(token_address)
                
                # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                original_data = next((t for t in tokens_to_analyze if 
                    (t.get('address') == token_address) or 
                    (t.get('token_address') == token_address) or
                    (t.get('basic_info', {}).get('address') == token_address)), {})
                report.external_checks['original_data'] = original_data
                
                analyzed_tokens.append(report.model_dump())
                
                print(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω - –†–∏—Å–∫: {report.risk_assessment.risk_level.value}")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {token_address}: {e}")
                continue
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.save_results(analyzed_tokens, output_file)
        print(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–∫–∏
        self.generate_summary(analyzed_tokens)
    
    def load_tokens_data(self, file_path: str) -> List[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –¥–∞–Ω–Ω—ã—Ö
            if isinstance(data, dict):
                if 'tokens' in data:
                    return data['tokens']
                elif 'results' in data:
                    return data['results']
                elif 'recommended_tokens' in data:
                    tokens = data['recommended_tokens']
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ risk_distribution
                    if 'risk_distribution' in data:
                        print(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤: {data['risk_distribution']}")
                    return tokens
                else:
                    return [data]
            elif isinstance(data, list):
                return data
            else:
                print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –≤ {file_path}")
                return []
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞ {file_path}: {e}")
            return []
    
    def filter_tokens(self, tokens: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ç–æ–∫–µ–Ω–æ–≤ (–∏—Å–∫–ª—é—á–µ–Ω–∏–µ –ø–æ–º–µ—á–µ–Ω–Ω—ã—Ö –∫–∞–∫ scam)"""
        filtered = []
        
        for token in tokens:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ scam
            scam_indicators = [
                token.get('is_scam', False),
                token.get('scam', False),
                token.get('risk_level', '').lower() == 'scam',
                token.get('status', '').lower() == 'scam',
                token.get('type', '').lower() == 'scam'
            ]
            
            # –ï—Å–ª–∏ —Ç–æ–∫–µ–Ω –ø–æ–º–µ—á–µ–Ω –∫–∞–∫ scam, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –µ–≥–æ
            if any(scam_indicators):
                print(f"‚è≠Ô∏è  –ü—Ä–æ–ø—É—Å–∫ scam —Ç–æ–∫–µ–Ω–∞: {token.get('address', 'Unknown')}")
                continue
            
            filtered.append(token)
        
        return filtered
    
    def save_results(self, results: List[Dict[str, Any]], output_file: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            output_data = {
                'analysis_timestamp': asyncio.get_event_loop().time(),
                'total_tokens_analyzed': len(results),
                'analysis_type': 'free',
                'results': results
            }
            
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, indent=2, default=str)
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
    
    def generate_summary(self, results: List[Dict[str, Any]]):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
        if not results:
            return
        
        print("\n" + "="*50)
        print("üìä –°–í–û–î–ù–´–ô –û–¢–ß–ï–¢")
        print("="*50)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∏—Å–∫–æ–≤
        risk_counts = {}
        total_time = 0
        verified_count = 0
        renounced_count = 0
        locked_count = 0
        
        for result in results:
            risk_level = result.get('risk_assessment', {}).get('risk_level', 'UNKNOWN')
            risk_counts[risk_level] = risk_counts.get(risk_level, 0) + 1
            
            analysis_time = result.get('analysis_duration', 0)
            total_time += analysis_time
            
            if result.get('contract_analysis', {}).get('verified', False):
                verified_count += 1
            
            if result.get('ownership', {}).get('renounced', False):
                renounced_count += 1
            
            if result.get('distribution', {}).get('liquidity_locked', False):
                locked_count += 1
        
        print(f"üìà –í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Ç–æ–∫–µ–Ω–æ–≤: {len(results)}")
        print(f"‚è±Ô∏è  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {total_time/len(results):.2f}—Å")
        
        print(f"\nüéØ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–æ–≤:")
        for risk, count in risk_counts.items():
            percentage = (count / len(results)) * 100
            print(f"  {risk}: {count} —Ç–æ–∫–µ–Ω–æ–≤ ({percentage:.1f}%)")
        
        print(f"\nüîß –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  ‚Ä¢ –í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤: {verified_count}/{len(results)}")
        print(f"  ‚Ä¢ –†–µ–Ω–æ–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤: {renounced_count}/{len(results)}")
        print(f"  ‚Ä¢ –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç–∏: {locked_count}/{len(results)}")
        
        print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        if risk_counts.get('CRITICAL', 0) > 0:
            print(f"  ‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {risk_counts['CRITICAL']} –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏ –æ–ø–∞—Å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤")
        if risk_counts.get('HIGH', 0) > 0:
            print(f"  ‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {risk_counts['HIGH']} –≤—ã—Å–æ–∫–æ—Ä–∏—Å–∫–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤")
        if renounced_count < len(results) * 0.5:
            print(f"  ‚ö†Ô∏è  –ú–µ–Ω–µ–µ 50% —Ç–æ–∫–µ–Ω–æ–≤ –∏–º–µ—é—Ç —Ä–µ–Ω–æ–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤–ª–∞–¥–µ–ª—å—Ü–µ–≤")
        if locked_count < len(results) * 0.3:
            print(f"  ‚ö†Ô∏è  –ú–µ–Ω–µ–µ 30% —Ç–æ–∫–µ–Ω–æ–≤ –∏–º–µ—é—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–Ω—É—é –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å")

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    processor = TokenProcessor()
    
    # –ü—É—Ç–∏ –∫ —Ñ–∞–π–ª–∞–º
    input_file = "results/final_recommended_20250811_183555.json"
    output_file = "results/free_analysis_results.json"
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    if not os.path.exists(input_file):
        print(f"‚ùå –í—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {input_file}")
        print("üí° –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª —Å —Ç–æ–∫–µ–Ω–∞–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON")
        return
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ–∫–µ–Ω–æ–≤
    await processor.process_tokens_file(input_file, output_file)
    
    print("\nüéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")

if __name__ == "__main__":
    asyncio.run(main())
